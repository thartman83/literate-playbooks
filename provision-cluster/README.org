#+TITLE: Provision a VM Cluster
#+AUTHOR: Tom Hartman
* General

The purpose of this playbook is to spin up and down a set of bare virtual machines capable of being used in a kubernetes cluster on a vm host. These vms will be minimally configured to allow for ssh login and have a python instance install to allow for future ansible blaybooks to be run. The goal is to be able to spin up blank virtual machines that can be used for setting up small clusters for testing and development purposes. As a result, I do not consider these virtual machines to be permanent or anything other than ephemeral for non-production usage.

** Requirements and Prerequisites
There is very little in the way of prerequisites other than a linux host that can do hardware emulation and virtualization. As of this writing I’m running this on an old NUC that I was being used as a media server so I’m not expecting it to win any races in terms of speed but should be good enough for development and testing purposes even if it runs a bit slow.

** Assumptions
There will be one or two tasks that are Arch Linux specific, but those are solely for verifying and installing if necessary the appropriate qemu packages. I will note those in the tasks section when applicable. They should be changed to reflect the hosts distribution package manager as needed.

** Risks
This playbook obviously will also be spinning up new virtual machines which could cause issues in terms of consuming resources on the host machine. Additionally, this playbook has the capability of unprovisioning virtual machines. This will destroy the virtual machine as well as any virtual disk associated with the vm. Both options will have options to `check` the target environment both that it will be able to complete the action based on the resources available as well as report back what will be created/destroyed. It is recommended to run these checks prior to running to confirm that you will get the desired outcome.

** Naming Conventions
I will primarily be calling the target host where the virtual machines are create the `VM host’ and the virtual machines within it sa `VMs’ however all of them do need actual host names as well. Within this document the VM host will be named anemoi and the VMs will be boreas, zephyrus, notus, and eurus after the four winds of Greek mythology. These will only be referenced in any file that actual requires using their actual host name and otherwise will be referred to in the more generic sense.

** Usage

To run this playbook use the following command.

#+begin_src sh
ansible-playbook -i inventory/hosts main.yml --extra-args action=[action]
#+end_src

The action key value pair will determine what type of action the playbook will take on the vmhost system. These actions are as follows:

- check-provision: Check that the target system is capable of provisioning the virtual machines. It will both perform a check to see that the CPU support virtualization as well as if the host has enough resources to create and run the virtual machines in terms of memory and storage.

- provision: Create the virtual machines based on the values in the vms group. This will create new images for the virtual machines, do minimal configuration of the images so that they are ansible ready, and finally create the virtual machines using the customized image.

- check-unprovision:

- unprovision:

* Inventory

The playbook expects the following host groups be defined

- vmhost
  The host (or hosts) machine where the virtual machines will be created and started.
- vms
  A list of virtual machines to be created on the target machine.

  The number of vmhosts and VMs is entirely arbitrary though at least one will need to be defined for each. For the rest of this documentation the assumption will be that there is a single VM host named anemoi and 4 vms to be managed: boreas, zephyrus, notus, and eurus. These are defined in inventory/hosts.ini as below:

#+begin_src yaml :tangle inventory/hosts.ini
[vmhost]
anemoi

[vms]
boreas
zephyrus
notus
eurus
#+end_src

* Host Variables

Setup the variables for each host in their own respective file. These files need to be the same name as the name of the host in the hosts file if using dns. If it is being referenced by IP address the below yaml file should be name the IP address, eg: 172.17.1.123.yml

For the VM host we will define the package names based on the host operating system. The package names below are for arch so adjust accordingly if they are not the same for the target operating system

#+begin_src yaml :tangle host_vars/anemoi.yml
---
qemu_package: qemu
dhclient_package: dhclient
openbsd_netcat_package: openbsd-netcat
dnsmasq_package: dnsmasq
virt_install_package: virt-install
bridge_utils_package: bridge-utils
qemu_img_package: qemu-img
libvirt_package: libvirt
#+end_src

Additionally we will want to define the name of the services in case they are different across distributions
#+begin_src yaml :tangle host_vars/anemoi.yml
libvirtd_service: libvirtd
#+end_src

Directories:

#+begin_src yaml :tangle host_vars/anemoi.yml
vm_working_dir: /tmp/vm_imgs/

#+end_src

For the VMs we will be using the cloud buster debian vm image as a base. It will be configured on a per VM basis with other configurations throughout the playbook process.

#+begin_src yaml :tangle host_vars/anemoi.yml
vm_img_baseurl: https://cloud.debian.org/images/cloud/buster/
vm_img_release_date: 20230802-1460
vm_img_name: "debian-10-generic-arm64-{{ vm_img_release_date }}.qcow2"
vm_download_url: "{{ vm_img_baseurl }}/{{ vm_img_release_date }}/{{ vm_img_name }}"
#+end_src

For the VMs themselves we will create identical machines provisioned with the same amount of disk space and memory. By default this playbook will provision each with 20G of disk space, 2G of memory, a default user of `anemoi` using the ssh public key ~/.ssh/anemoi_rsa as an authorized key.

#+begin_src yaml :tangle host_vars/anemoi.yml
vm_diskspace: 20G
vm_memory: 2G
user: anemoi
ssh_pub_key: ~/.ssh/anemoi_rsa
#+end_src

* Playbook Definitions

The playbook is invoked by called the main.yml file within this directory.

** Main

The main.yml file is the entry point for this playbook and will be used in combination with the action parameter to determine which roles will be run against the host.

We begin with a general playbook definition and setup, providing the name, the hosts to run against as well as indicating that this playbook will be run as the root user `become: true’.

#+begin_src yaml :tangle main.yml
---
- name: Provision virtual machines
  hosts: vmhost
  become: true
  roles:
    - role: virtualization-checks
    - role: virtualization-packages
    - role: virtualization-services
    - role: prepare-vm-dirs
    - role: download-vm-image
  #+end_src

** Roles

*** Virtualization Checks

The `virtualization checks` role will check that the target host(s) is capable of virtualization as a basic sanity check prior to beginning any other tasks or roles within this playbook.

The easiest way to achieve this is to use the `lscpu` utility and check the value of the Virtualization property of the CPU. We are looking for a value of VT-x for Intel chipsets or AMD-V for AMD. Were we to look at this by hand we would run:

#+begin_src sh
LC_ALL=C lscpu | grep Virtualization
#+end_src

We should see something like this as a result:
#+begin_src text
Virtualization:                  VT-x
#+end_src

We set LC_ALL=C to turn off any internationalization locales on the target system so that the results will come back in english (as the default) before we pass that to grep. I believe these days the C locale is really just POSIX but out of habit I still use C. The task to perform the check is as follows.

#+begin_src yaml :tangle roles/virtualization-checks/tasks/main.yml
---

- name: Verify virtualization capabilities of the host
  shell:
    cmd: |-
      LC_ALL=C lscpu | grep Virtualization: | sed -e 's/^.*Virtualization:\s*\(.*\)\s*$/\1/'
  register: ret
  failed_when: ret.stdout != 'VT-x' and ret.stdout != 'AMD-V'
#+end_src

*** Virtualization Packages

We will need the following packages to be installed on the VM host in order to setup the various VMs. We will use the generic package task action and rely on the host_vars defined in [[*Host Variables][Host Variables]]. If the name of the values in different package names for you OS please update before running this task.

#+begin_src yaml :tangle roles/virtualization-packages/tasks/main.yml
---

- name: Verify installation of virtualization packages
  package:
    name:
      - "{{ qemu_package }}"
      - "{{ dhclient_package }}"
      - "{{ openbsd_netcat_package }}"
      - "{{ dnsmasq_package }}"
      - "{{ virt_install_package }}"
      - "{{ bridge_utils_package }}"
      - "{{ qemu_img_package }}"
      - "{{ libvirt_package }}"
    state: present

#+end_src

*** Virtualization Services

We will also need to make sure that the libvirtd service has been started. Again we will be using the generic service package.

#+begin_src yaml :tangle roles/virtualization-services/tasks/main.yml
---

- name: Start the libvirtd service
  service:
    name: "{{ libvirtd_service }}"
    state: started
    enabled: true
#+end_src

***

*** Prepare VM Image Directories

#+begin_src yaml :tangle roles/prepare-vm-dirs/tasks/main.yml
---

- name: Prepare Temp Directory for VM image creation
  file:
    path: "{{ vm_working_dir }}"
    state: directory

#+end_src

*** Download the base VM image

#+begin_src yaml :tangle roles/download-vm-image/tasks/main.yml
- name: Download the base VM image
  get_url:
    url: "{{ vm_download_url }}"
    dest: "{{ vm_working_dir }}"

#+end_src
